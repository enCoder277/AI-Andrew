"""
–ø–µ—Ä–µ–≤–µ—Å—Ç–∏ –Ω–∞ API llm
–≤–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–∏ –≤–æ–¥–µ (message)
—Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞ –∏ –ø–∞–º—è—Ç—å —á–∞—Ç–∞
—Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –≤—ã–±–æ—Ä –º–µ–∂–¥—É —Ç–µ–∫—Å—Ç–æ–º –∏ –≥—Å
–¥–æ–¥–µ–ª–∞—Ç—å help
–≤—ã–≤–æ–¥ –≥—Å
"""

import asyncio
import ollama
import logging
from decouple import config
from elevenlabs import save
from elevenlabs.client import ElevenLabs
from aiogram import Bot, Dispatcher, types, F
from aiogram.types import FSInputFile
from aiogram.filters.command import Command


# –ª–æ–≥–∏
logging.basicConfig(level=logging.INFO)
BOT_TOKEN = config('TELEGRAM_BOT_TOKEN')
bot = Bot(token=BOT_TOKEN)
dp = Dispatcher()

ELEVENLABS_KEY = config('ELEVENLABS_TOKEN')
client = ElevenLabs(api_key=ELEVENLABS_KEY)

@dp.message(Command("start"))
async def cmd_start(message: types.Message):
    description = (
        "‚ú® –ü—Ä–∏–≤–µ—Ç! –Ø —Ç–≤–æ–π –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫, —Å–æ–∑–¥–∞–Ω–Ω—ã–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞! ‚ú®\n\n"
        "üí¨ –ì–æ—Ç–æ–≤ –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ —Ç–≤–æ–∏ –≤–æ–ø—Ä–æ—Å—ã, –ø–æ–¥–¥–µ—Ä–∂–∞—Ç—å —Ä–∞–∑–≥–æ–≤–æ—Ä –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ —Å—Ç–∞—Ç—å —Å–æ–±–µ—Å–µ–¥–Ω–∏–∫–æ–º.\n"
        "ü§ñ –ò—Å–ø–æ–ª—å–∑—É—é –ø–µ—Ä–µ–¥–æ–≤—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏, —á—Ç–æ–±—ã –ø–æ–º–æ—á—å —Ç–µ–±–µ –Ω–∞—Ö–æ–¥–∏—Ç—å —Ä–µ—à–µ–Ω–∏—è, –¥–µ–ª–∏—Ç—å—Å—è –∑–Ω–∞–Ω–∏—è–º–∏ –∏ –ø—Ä–æ—Å—Ç–æ "
        "–¥–µ–ª–∞—Ç—å —Ç–≤–æ–π –¥–µ–Ω—å —á—É—Ç–æ—á–∫—É –∏–Ω—Ç–µ—Ä–µ—Å–Ω–µ–µ!\n\n"
        "–î–∞–≤–∞–π –ø–æ–≥–æ–≤–æ—Ä–∏–º? üòä"
    )
    await message.answer(description)

@dp.message(Command("help"))
async def cmd_help(message: types.Message):
    help_text = (
        "üõ† Help:\n\n"
        "–Ø –±–æ—Ç, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π –º–æ–¥–µ–ª—å –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞. "
        "–í—ã –º–æ–∂–µ—Ç–µ –∑–∞–¥–∞—Ç—å –º–Ω–µ –ª—é–±–æ–π –≤–æ–ø—Ä–æ—Å –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ –ø–æ–≥–æ–≤–æ—Ä–∏—Ç—å. üòä\n\n"
        "–ü–æ–ø—Ä–æ–±—É–π –Ω–∞–ø–∏—Å–∞—Ç—å —á—Ç–æ-–Ω–∏–±—É–¥—å, –∏ —è –ø–æ—Å—Ç–∞—Ä–∞—é—Å—å —Ç–µ–±–µ –ø–æ–º–æ—á—å!"
    )
    await message.answer(help_text)



def text_response_ollama(prompt: str, model_name: str = "your_model_name"):
    try:
        response = ollama.chat(model=model_name, messages=[{'role': 'user', 'content': prompt}])
        return response['message']['content']
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ Ollama: {e}")
        return "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ –º–æ–¥–µ–ª–∏."

ollama_voices = client.voices.get_all() #for optimization
def audio_response_ollama(prompt: str, model_name: str = "your_model_name") -> str:
    try:
        text_response = ollama.chat(model=model_name, messages=[{'role': 'user', 'content': prompt}])
        audio_response = client.generate(text=text_response['message']['content'], voice=ollama_voices.voices[3])
        save(audio_response, 'audio_response.mp3')

        return 'audio_response.mp3'
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ Ollama: {e}")
        return "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ –º–æ–¥–µ–ª–∏."




@dp.message(F.text)
async def handle_message(message: types.Message):
    USER_CHOICE = True # –±—É–¥–µ—Ç —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω –≤—ã–±–æ—Ä –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º

    user_text = message.text

    if USER_CHOICE == True:
        ollama_response = audio_response_ollama(user_text, "llama3.1:latest")
        audio_file = FSInputFile(ollama_response, filename='EXAMPLE')
        await message.answer_audio(audio=audio_file)
        await message.answer_voice(audio=audio_file) #- –ø–µ—Ä–µ–¥–∞—Ç—å —Å—é–¥–∞ —Å—Å—ã–ª–∫—É –Ω–∞ —Ñ–∞–π–ª (str) –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ —á–µ—Ä–µ–∑ InputFile.
    if USER_CHOICE == False:
        ollama_response = text_response_ollama(user_text, "llama3.1:latest")
        await message.answer(ollama_response)






# –ó–∞–ø—É—Å–∫ –ø—Ä–æ—Ü–µ—Å—Å–∞ –ø–æ–ª–ª–∏–Ω–≥–∞ –Ω–æ–≤—ã—Ö –∞–ø–¥–µ–π—Ç–æ–≤
async def main():
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())